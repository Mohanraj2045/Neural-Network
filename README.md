Basic Neural Network
Welcome to the Basic Neural Network repository! This project is a simple implementation of a neural network from scratch,
designed to help beginners understand the fundamentals of neural networks.

Overview
This basic neural network is implemented in Python using only basic libraries such as NumPy. 
It serves as a starting point for those who want to grasp the core concepts of neural networks without the complexities of larger frameworks.

Features
Feedforward Neural Network: The implementation includes a simple feedforward neural network architecture.
Activation Functions: You can find commonly used activation functions such as tanh.
Gradient Descent: The network uses gradient descent for optimizing the weights during training.
Loss Function: Cross-entropy loss is implemented for classification tasks.
Contributing
Contributions are welcome! Feel free to open issues, submit pull requests, or provide feedback. 
Acknowledgments
Special thanks to Andrej Karpathy for his invaluable contributions to the field of deep learning and for his insightful explanations.
This implementation is inspired by his teachings and the illuminating lecture available in this [video.](https://youtu.be/VMj-3S1tku0?si=ePJGbFWhm16sloVV)
