{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tenpy:\n",
    "\n",
    "    def __init__ (self,data,prev = (),op = '',label = ''):\n",
    "        self.data = data\n",
    "        self.type = type(data)\n",
    "        self.prev = set(prev)\n",
    "        self._backword = lambda: None\n",
    "        self.op = op\n",
    "        self.label = label\n",
    "        self.grad = 0\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"tenpy(data  = {self.data}   {self.type})\"\n",
    "    \n",
    "    def __add__(self,other):\n",
    "\n",
    "        other = other if isinstance(other,tenpy) else tenpy(other)\n",
    "\n",
    "        new =  tenpy( self.data + other.data , (self,other),'+')\n",
    "\n",
    "        def _backword():\n",
    "\n",
    "            self.grad += 1.0 *new.grad\n",
    "            other.grad += 1.0 *new.grad\n",
    "\n",
    "        new._backword = _backword\n",
    "        return new\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def __radd__(self,other):\n",
    "         \n",
    "         return self+other\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __mul__(self,other):\n",
    "\n",
    "        other = other if isinstance(other,tenpy) else tenpy(other)\n",
    "\n",
    "        \n",
    "        new = tenpy( self.data * other.data , (self,other),'*') \n",
    "        def _backword():\n",
    "            self.grad +=  other.data *new.grad\n",
    "            other.grad += self.data *new.grad\n",
    "        \n",
    "        new._backword = _backword\n",
    "\n",
    " \n",
    "        return new\n",
    "    \n",
    "    def __rmul__(self,other):\n",
    "        return self * other\n",
    "    \n",
    "\n",
    "\n",
    "    def __truediv__(self,other):\n",
    "        return self*(other**-1)\n",
    "    \n",
    "\n",
    "\n",
    "    def __pow__(self,other):\n",
    "\n",
    "        assert isinstance(other,(float,int))\n",
    "\n",
    "        new = tenpy(self.data**other,(self,),f'**{other}')\n",
    "\n",
    "        def _backword():\n",
    "            self.grad +=  other *(self.data**(other -1)) * new.grad    \n",
    "        \n",
    "        new._backword = _backword\n",
    "        \n",
    "\n",
    "        \n",
    "        return new\n",
    "\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return (self**-1)*other\n",
    "\n",
    "    def __sub__(self,other):\n",
    "        return self +(-other)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self*-1\n",
    "    \n",
    "    def exp(self):\n",
    "\n",
    "        new = tenpy(math.exp(self.data),(self,),\"exp\")\n",
    "\n",
    "        def _backword():\n",
    "\n",
    "            self.grad += new.data * new.grad\n",
    "\n",
    "        new._backword = _backword\n",
    "\n",
    "        return new\n",
    "    \n",
    "    def tanh(self):\n",
    "\n",
    "        x2 =  2*self.data\n",
    "        ex2 =  math.exp(x2)\n",
    "        sinh = ex2 - 1\n",
    "        cosh = ex2 + 1\n",
    "        new = tenpy(sinh/cosh , (self,),\"tanh\")\n",
    "\n",
    "        def _backword():\n",
    "           \n",
    "            self.grad +=  (1 -new.data**2)*new.grad\n",
    "\n",
    "        new._backword = _backword\n",
    "        return new  \n",
    "    \n",
    "    def backword(self):\n",
    "\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(val):\n",
    "            if val not in visited:\n",
    "                visited.add(val)\n",
    "                for  child in val.prev:\n",
    "                    \n",
    "                    build_topo(child)\n",
    "                topo.append(val)\n",
    "        \n",
    "        build_topo(self)\n",
    "        self.grad = 1\n",
    "        for child in reversed(topo):\n",
    "            child._backword()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(val):\n",
    "    nodes = set()\n",
    "    edges = set()\n",
    "    def get(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for i in v.prev:\n",
    "                edges.add((i,v))\n",
    "                get(i)\n",
    "    get(val)\n",
    "    return nodes,edges\n",
    "\n",
    "def visuvalize(val):\n",
    "\n",
    "    plot = Digraph(format='svg',graph_attr= {'rankdir':'LR'})\n",
    "\n",
    "    nodes , edges = trace(val)\n",
    "\n",
    "    for node in nodes:\n",
    "\n",
    "        uid = str(id(node))\n",
    "        plot.node( name = uid, label= f\"{node.label}|data = {node.data}|grad = {node.grad}\", shape = 'record')\n",
    "\n",
    "        if node.op:\n",
    "            plot.node(name = uid+ node.op , label= node.op)\n",
    "            plot.edge(uid+node.op , uid)\n",
    "\n",
    "    for n1,n2 in edges:\n",
    "        plot.edge(str(id(n1)),str(id(n2))+n2.op)\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self,inp):\n",
    "        self.W = [tenpy(random.uniform(-1,1)) for i in range(inp)]\n",
    "        self.b = tenpy(random.uniform(-1,1))\n",
    "        self.inp = inp\n",
    "    def __call__(self,x):\n",
    "        \n",
    "        act =sum((wi*xi for wi, xi in zip(self.W, x)), self.b)\n",
    "        \n",
    "        return(act.tanh())\n",
    "    \n",
    "    def parameter(self):\n",
    "\n",
    "        return  self.W + [self.b]\n",
    "    \n",
    "class Layer:\n",
    "\n",
    "    def __init__(self,inp,op):\n",
    "\n",
    "        self.neurons = [Neuron(inp) for i in range(op)]\n",
    "    \n",
    "    def __call__(self,x):\n",
    "\n",
    "        outs = [neuron(x) for neuron in self.neurons]\n",
    "\n",
    "        return outs[0] if len(outs)==1 else outs\n",
    "    \n",
    "    def parameter(self):\n",
    "\n",
    "        return [p for neuron in self.neurons for p in neuron.parameter()]\n",
    "    \n",
    "class MLP:\n",
    "\n",
    "    def __init__(self,inp,ops):\n",
    "\n",
    "        N = [inp] + list(ops)\n",
    "\n",
    "        self.layers = [Layer(N[i],N[i+1]) for i in range(len(N) - 1)]\n",
    "\n",
    "    def __call__(self,x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def parameter(self):\n",
    "\n",
    "        return [p for layer in self.layers for p in layer.parameter()]\n",
    "    \n",
    "    def reset_grade(self):\n",
    "\n",
    "        for p in self.parameter():\n",
    "\n",
    "            p.grad = 0\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        for p in self.parameter():\n",
    "\n",
    "            p.data += -0.1*p.grad\n",
    "\n",
    "    def fit(self,xs,ys,epochs):\n",
    "\n",
    "        for i in range(epochs):\n",
    "\n",
    "            ypred = [self(x) for x in xs]\n",
    "            loss = sum((yp - y)**2 for yp,y in zip(ypred,ys))\n",
    "            self.reset_grade()\n",
    "            loss.backword()\n",
    "            self.update_weights()\n",
    "            print(loss)\n",
    "\n",
    "    def predict(self,xs: list[list[(int,float)]]):\n",
    "\n",
    "        mypred  = [self(x) for x in xs]\n",
    "        \n",
    "        return mypred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, -1.0, -1.0],\n",
    " [1.0, 1.0, -1.0] ,\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0,-1] # desired targets\n",
    "\n",
    "len1 = len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = MLP(3,[4,4,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenpy(data  = 7.334242603261702   <class 'float'>)\n",
      "tenpy(data  = 4.761633944073488   <class 'float'>)\n",
      "tenpy(data  = 9.274724053843192   <class 'float'>)\n",
      "tenpy(data  = 3.6160108650057694   <class 'float'>)\n",
      "tenpy(data  = 4.2320353771965316   <class 'float'>)\n",
      "tenpy(data  = 5.948517981181035   <class 'float'>)\n",
      "tenpy(data  = 3.0143589487500977   <class 'float'>)\n",
      "tenpy(data  = 2.837997355771375   <class 'float'>)\n",
      "tenpy(data  = 2.95584353133582   <class 'float'>)\n",
      "tenpy(data  = 2.733836417483152   <class 'float'>)\n",
      "tenpy(data  = 2.818911348660561   <class 'float'>)\n",
      "tenpy(data  = 2.6811204236020965   <class 'float'>)\n",
      "tenpy(data  = 3.2530369378142434   <class 'float'>)\n",
      "tenpy(data  = 2.2310473435205234   <class 'float'>)\n",
      "tenpy(data  = 3.011408939002864   <class 'float'>)\n",
      "tenpy(data  = 3.544471554006099   <class 'float'>)\n",
      "tenpy(data  = 5.12294450814724   <class 'float'>)\n",
      "tenpy(data  = 3.575299293975994   <class 'float'>)\n",
      "tenpy(data  = 3.3036331166153805   <class 'float'>)\n",
      "tenpy(data  = 2.951261364026519   <class 'float'>)\n",
      "tenpy(data  = 2.758689289873648   <class 'float'>)\n",
      "tenpy(data  = 2.7211511343076262   <class 'float'>)\n",
      "tenpy(data  = 2.705983353118713   <class 'float'>)\n",
      "tenpy(data  = 2.697462845289329   <class 'float'>)\n",
      "tenpy(data  = 2.6928160106695422   <class 'float'>)\n",
      "tenpy(data  = 2.692831320826642   <class 'float'>)\n",
      "tenpy(data  = 2.6956209499256634   <class 'float'>)\n",
      "tenpy(data  = 2.7135836418846173   <class 'float'>)\n",
      "tenpy(data  = 2.725306057988185   <class 'float'>)\n",
      "tenpy(data  = 2.793791210031237   <class 'float'>)\n",
      "tenpy(data  = 2.762711339328087   <class 'float'>)\n",
      "tenpy(data  = 2.8839358228443643   <class 'float'>)\n",
      "tenpy(data  = 2.739948316571915   <class 'float'>)\n",
      "tenpy(data  = 2.84167410077141   <class 'float'>)\n",
      "tenpy(data  = 2.7478133250905685   <class 'float'>)\n",
      "tenpy(data  = 2.8672572541448593   <class 'float'>)\n",
      "tenpy(data  = 2.734527296546294   <class 'float'>)\n",
      "tenpy(data  = 2.8487304819540196   <class 'float'>)\n",
      "tenpy(data  = 2.7355968459241584   <class 'float'>)\n",
      "tenpy(data  = 2.8657677401379567   <class 'float'>)\n",
      "tenpy(data  = 2.7239162252787015   <class 'float'>)\n",
      "tenpy(data  = 2.859402901035341   <class 'float'>)\n",
      "tenpy(data  = 2.7209250102823717   <class 'float'>)\n",
      "tenpy(data  = 2.881485454436072   <class 'float'>)\n",
      "tenpy(data  = 2.7043809063866435   <class 'float'>)\n",
      "tenpy(data  = 2.8817639726912105   <class 'float'>)\n",
      "tenpy(data  = 2.6985723228635132   <class 'float'>)\n",
      "tenpy(data  = 2.9237524706454816   <class 'float'>)\n",
      "tenpy(data  = 2.66262538891562   <class 'float'>)\n",
      "tenpy(data  = 2.9020919519266184   <class 'float'>)\n",
      "tenpy(data  = 2.6763019400532078   <class 'float'>)\n",
      "tenpy(data  = 3.039992516391316   <class 'float'>)\n",
      "tenpy(data  = 2.533110282611748   <class 'float'>)\n",
      "tenpy(data  = 2.6884746479393913   <class 'float'>)\n",
      "tenpy(data  = 2.9448298281222596   <class 'float'>)\n",
      "tenpy(data  = 3.6250099765736765   <class 'float'>)\n",
      "tenpy(data  = 3.2966079545257094   <class 'float'>)\n",
      "tenpy(data  = 2.5794863986027936   <class 'float'>)\n",
      "tenpy(data  = 2.6457776638647132   <class 'float'>)\n",
      "tenpy(data  = 3.1821390000370693   <class 'float'>)\n",
      "tenpy(data  = 2.3303947585169555   <class 'float'>)\n",
      "tenpy(data  = 2.1977873450939622   <class 'float'>)\n",
      "tenpy(data  = 2.1530060403316007   <class 'float'>)\n",
      "tenpy(data  = 4.495197498488674   <class 'float'>)\n",
      "tenpy(data  = 3.8768795290909743   <class 'float'>)\n",
      "tenpy(data  = 3.824594957887768   <class 'float'>)\n",
      "tenpy(data  = 3.741828358463893   <class 'float'>)\n",
      "tenpy(data  = 3.5855813503876552   <class 'float'>)\n",
      "tenpy(data  = 3.2401663981587965   <class 'float'>)\n",
      "tenpy(data  = 2.610127176989575   <class 'float'>)\n",
      "tenpy(data  = 2.556532488795507   <class 'float'>)\n",
      "tenpy(data  = 2.6625689920340547   <class 'float'>)\n",
      "tenpy(data  = 2.7474078368145802   <class 'float'>)\n",
      "tenpy(data  = 3.5082890501494517   <class 'float'>)\n",
      "tenpy(data  = 2.8382707981686885   <class 'float'>)\n",
      "tenpy(data  = 2.569536507550191   <class 'float'>)\n",
      "tenpy(data  = 3.50114354130569   <class 'float'>)\n",
      "tenpy(data  = 2.8165151176556242   <class 'float'>)\n",
      "tenpy(data  = 2.5426334396565426   <class 'float'>)\n",
      "tenpy(data  = 3.6084958934809697   <class 'float'>)\n",
      "tenpy(data  = 3.206855969318699   <class 'float'>)\n",
      "tenpy(data  = 2.2347683413398407   <class 'float'>)\n",
      "tenpy(data  = 2.5553836334845985   <class 'float'>)\n",
      "tenpy(data  = 3.7769358684645464   <class 'float'>)\n",
      "tenpy(data  = 3.6233312845951455   <class 'float'>)\n",
      "tenpy(data  = 3.3208981320118727   <class 'float'>)\n",
      "tenpy(data  = 2.7770946949691098   <class 'float'>)\n",
      "tenpy(data  = 2.6719714609957252   <class 'float'>)\n",
      "tenpy(data  = 2.6551687386423892   <class 'float'>)\n",
      "tenpy(data  = 2.522889446565718   <class 'float'>)\n",
      "tenpy(data  = 2.290696651184448   <class 'float'>)\n",
      "tenpy(data  = 3.5416892242480396   <class 'float'>)\n",
      "tenpy(data  = 3.7990075768349247   <class 'float'>)\n",
      "tenpy(data  = 3.6873607365789827   <class 'float'>)\n",
      "tenpy(data  = 3.4764014571504194   <class 'float'>)\n",
      "tenpy(data  = 3.0490684321267985   <class 'float'>)\n",
      "tenpy(data  = 2.682051674559869   <class 'float'>)\n",
      "tenpy(data  = 2.6728295914280062   <class 'float'>)\n",
      "tenpy(data  = 2.664458589895064   <class 'float'>)\n",
      "tenpy(data  = 2.6570015109438394   <class 'float'>)\n"
     ]
    }
   ],
   "source": [
    "n.fit(xs,ys,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tenpy(data  = 0.2820951378817281   <class 'float'>),\n",
       " tenpy(data  = -0.9621524470623408   <class 'float'>),\n",
       " tenpy(data  = -0.9709960711369958   <class 'float'>),\n",
       " tenpy(data  = 0.2933238091059199   <class 'float'>),\n",
       " tenpy(data  = 0.27701423749114307   <class 'float'>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056168177404032196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.parameter()[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.reset_grade()\n",
    "n.parameter()[0].grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
